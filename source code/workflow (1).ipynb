{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SRguybVlKGc"
      },
      "source": [
        "[texte du lien](https://)# [import video ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZUZMEDCk38k",
        "outputId": "9a130bf0-db36-40d0-d9e5-71ab6a4d9023"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repository downloaded successfully and saved to /content/Car-Detection-main.zip\n",
            "Repository extracted successfully to /content/Car-Detection\n",
            "Cleaned up the zip file: /content/Car-Detection-main.zip\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# URL of the GitHub repository's zip file\n",
        "repo_url = \"https://github.com/fedei10/Car-Detection/archive/refs/heads/main.zip\"\n",
        "repo_path = \"/content/Car-Detection\"  # Directory where the repository will be extracted\n",
        "\n",
        "# Download the zip file\n",
        "response = requests.get(repo_url, stream=True)\n",
        "zip_path = \"/content/Car-Detection-main.zip\"\n",
        "if response.status_code == 200:\n",
        "    with open(zip_path, \"wb\") as f:\n",
        "        for chunk in response.iter_content(chunk_size=8192):\n",
        "            f.write(chunk)\n",
        "    print(f\"Repository downloaded successfully and saved to {zip_path}\")\n",
        "else:\n",
        "    print(f\"Failed to download the repository. Status code: {response.status_code}\")\n",
        "\n",
        "# Extract the zip file\n",
        "if os.path.exists(zip_path):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"/content\")\n",
        "    print(f\"Repository extracted successfully to {repo_path}\")\n",
        "\n",
        "# Clean up: Remove the downloaded zip file\n",
        "os.remove(zip_path)\n",
        "print(f\"Cleaned up the zip file: {zip_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Zx-ObXGLKs3C"
      },
      "outputs": [],
      "source": [
        "matricule_model_path = \"/content/Car-Detection-main/models/plate_detection.pt\"  # Your plate detection model\n",
        "safe_driving_model_path = \"/content/Car-Detection-main/models/yolo_classification.pt\"  # Your safe driving model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0LI-iGnKBh6",
        "outputId": "46c6cc98-03ec-4328-aa15-ab4b2957d4cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.50-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.50-py3-none-any.whl (898 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.0/899.0 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.50 ultralytics-thop-2.0.13\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
            "Collecting easyocr\n",
            "  Downloading easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.20.1+cu121)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from easyocr) (4.10.0.84)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from easyocr) (11.0.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.24.0)\n",
            "Collecting python-bidi (from easyocr)\n",
            "  Downloading python_bidi-0.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from easyocr) (6.0.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.0.6)\n",
            "Collecting pyclipper (from easyocr)\n",
            "  Downloading pyclipper-1.3.0.post6-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting ninja (from easyocr)\n",
            "  Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->easyocr) (1.3.0)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2.36.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2024.12.12)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->easyocr) (3.0.2)\n",
            "Downloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.9/422.9 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post6-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (912 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m912.2/912.2 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_bidi-0.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (286 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.8/286.8 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-bidi, pyclipper, ninja, easyocr\n",
            "Successfully installed easyocr-1.7.2 ninja-1.11.1.3 pyclipper-1.3.0.post6 python-bidi-0.6.3\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics\n",
        "!pip install opencv-python\n",
        "!pip install easyocr\n",
        "!pip install Pillow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEODl5cLJ9te",
        "outputId": "0186ab44-1d09-4fe7-95a5-c13c676c9d59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import re\n",
        "import easyocr\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from ultralytics.utils.plotting import Annotator, colors\n",
        "\n",
        "\n",
        "# Log detected classes\n",
        "def log_detected_classes(results):\n",
        "    for result in results:\n",
        "        for box in result.boxes:\n",
        "            print(f\"Detected class: {int(box.cls)}, Confidence: {box.conf[0]:.2f}\")\n",
        "\n",
        "# Extract text from the plate using EasyOCR\n",
        "def read_text_with_easyocr(roi):\n",
        "    result = reader.readtext(roi, detail=0)\n",
        "    r = ' '.join(result)\n",
        "    print(f\"unclean text: {r}\")\n",
        "    r = re.sub(r'[\\u0660-\\u0669]', '', r)\n",
        "    cleaned_text = re.findall(r'\\d+', r)\n",
        "    plate = \"\"\n",
        "    print(f\"cleaned text {cleaned_text}\")\n",
        "    if len(cleaned_text) == 2:\n",
        "        left_numbers = cleaned_text[1]\n",
        "        right_numbers = cleaned_text[0]\n",
        "        plate = f\"{right_numbers} تونس {left_numbers}\"\n",
        "    elif len(cleaned_text) == 1:\n",
        "        left_numbers = cleaned_text[0]\n",
        "        plate = f\"ن.ت\"+left_numbers\n",
        "    return plate\n",
        "#Annotation With Arabic Font using Pillow\n",
        "def annotate_with_arabic_text(image, text, position, font_path=\"/content/Car-Detection-main/Matricule_Model/Traditional Arabic Regular.ttf\", font_size=40, color=(0, 255, 0)):\n",
        "    \"\"\"\n",
        "    Annotates the image with Arabic text using Pillow.\n",
        "    \"\"\"\n",
        "    # Convert OpenCV image to a Pillow image\n",
        "    pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    draw = ImageDraw.Draw(pil_image)\n",
        "\n",
        "    # Load the font\n",
        "    font = ImageFont.truetype(font_path, font_size)\n",
        "\n",
        "    # Add text to the image\n",
        "    draw.text(position, text, font=font, fill=color)\n",
        "\n",
        "    # Convert the Pillow image back to OpenCV format\n",
        "    annotated_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)\n",
        "    return annotated_image\n",
        "\n",
        "# Calculate the percentage of black pixels in the plate region\n",
        "def check_black_percentage(roi):\n",
        "    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
        "    _, thresh = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY_INV)\n",
        "    black_pixels = np.sum(thresh == 255)\n",
        "    total_pixels = roi.shape[0] * roi.shape[1]\n",
        "    black_percentage = (black_pixels / total_pixels) * 100\n",
        "    return black_percentage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ld1uo-sDpr3y",
        "outputId": "593d5b4d-15d5-4a6b-f8ac-ac4c1b318631"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:easyocr.easyocr:Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
            "WARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
          ]
        }
      ],
      "source": [
        "reader = easyocr.Reader(['en', 'ar'], gpu=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXR9joXwlR87"
      },
      "source": [
        "#  ***videos to frames***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oaHiaifoPckb"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "import easyocr\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import time\n",
        "\n",
        "\n",
        "# Global variables for tracking vehicle IDs and positions\n",
        "vehicle_speeds = {}  # Dictionary to store speed for each vehicle ID\n",
        "previous_positions = {}  # Previous positions of vehicle IDs\n",
        "\n",
        "# Constants for speed calculation\n",
        "FPS = 30  # Frame rate of the video\n",
        "PIXEL_TO_METER_RATIO = 0.05  # Conversion ratio: 1 pixel ≈ 0.05 meters (adjust based on your video)\n",
        "\n",
        "# Define paths to your models\n",
        "matricule_model_path = \"Matricule_Yolo11m.pt\"\n",
        "safe_driving_model_path = \"yolo_classification.pt\"\n",
        "\n",
        "\n",
        "def load_models():\n",
        "    try:\n",
        "        model = YOLO(\"yolo11x.pt\")  # Vehicle detection model\n",
        "        plate_model = YOLO(matricule_model_path)  # License plate detection model\n",
        "        safe_driving_model = YOLO(safe_driving_model_path)  # Person classification model\n",
        "        return model, plate_model, safe_driving_model\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading models: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "\n",
        "def calculate_speed(vid_id, current_pos):\n",
        "    if vid_id in previous_positions:\n",
        "        prev_pos = previous_positions[vid_id]\n",
        "        distance = np.linalg.norm(np.array(current_pos) - np.array(prev_pos))  # Euclidean distance\n",
        "        speed = (distance * PIXEL_TO_METER_RATIO) * FPS * 3.6  # Convert to km/h\n",
        "        vehicle_speeds[vid_id] = round(speed, 2)\n",
        "    else:\n",
        "        vehicle_speeds[vid_id] = 0.0  # Initial speed is zero\n",
        "    previous_positions[vid_id] = current_pos\n",
        "    return vehicle_speeds[vid_id]\n",
        "\n",
        "\n",
        "def read_text_with_easyocr(plate_roi):\n",
        "    reader = easyocr.Reader(['en'])\n",
        "    result = reader.readtext(plate_roi)\n",
        "    plate_text = \" \".join([res[1] for res in result])\n",
        "    return plate_text\n",
        "\n",
        "\n",
        "def annotate_with_arabic_text(frame, text, position):\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    font_scale = 0.5\n",
        "    color = (0, 255, 0)\n",
        "    thickness = 2\n",
        "    cv2.putText(frame, text, position, font, font_scale, color, thickness, cv2.LINE_AA)\n",
        "    return frame\n",
        "\n",
        "\n",
        "def process_frame(frame, model, plate_model, safe_driving_model):\n",
        "    # Run YOLO tracking\n",
        "    results = model.track(frame, persist=True, tracker=\"bytetrack.yaml\")  # Use ByteTrack for ID tracking\n",
        "\n",
        "    for result in results[0].boxes:\n",
        "        vid_id = int(result.id) if result.id else None\n",
        "        cls = int(result.cls)\n",
        "        x1, y1, x2, y2 = map(int, result.xyxy[0])\n",
        "\n",
        "        if cls == 2 and vid_id:  # Vehicle class\n",
        "            # Calculate speed\n",
        "            center_position = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
        "            speed = calculate_speed(vid_id, center_position)\n",
        "\n",
        "            # Draw vehicle bounding box and speed\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "            cv2.putText(frame, f\"ID: {vid_id} Speed: {speed} km/h\", (x1, y1 - 10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "            # Detect persons within the vehicle ROI\n",
        "            person_results = [box for box in results[0].boxes if int(box.cls) == 1]  # Person class\n",
        "            for person in person_results:\n",
        "                px1, py1, px2, py2 = map(int, person.xyxy[0])\n",
        "                if x1 <= px1 <= x2 and y1 <= py1 <= y2:  # Check if person is inside vehicle ROI\n",
        "                    # Extract person ROI and validate\n",
        "                    person_roi = frame[py1:py2, px1:px2]\n",
        "                    if person_roi.size > 0:  # Ensure ROI is not empty\n",
        "                        # Classify the driving state\n",
        "                        driving_results = safe_driving_model(person_roi, verbose=False)\n",
        "                        top_class_idx = int(driving_results[0].probs.top1)\n",
        "                        confidence = driving_results[0].probs.top1conf\n",
        "                        class_name = driving_results[0].names[top_class_idx]\n",
        "\n",
        "                        # Annotate the classification result\n",
        "                        label = f\"{class_name} ({confidence:.2f})\"\n",
        "                        cv2.putText(frame, label, (px1, py1 - 10),\n",
        "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
        "\n",
        "            # Detect license plates within vehicle ROI\n",
        "            vehicle_roi = frame[y1:y2, x1:x2]\n",
        "            if vehicle_roi.size > 0:  # Ensure ROI is not empty\n",
        "                plate_results = plate_model(vehicle_roi)\n",
        "                for plate in plate_results[0].boxes:\n",
        "                    px1, py1, px2, py2 = map(int, plate.xyxy[0])\n",
        "                    plate_roi = vehicle_roi[py1:py2, px1:px2]\n",
        "                    if plate_roi.size > 0:  # Ensure ROI is not empty\n",
        "                        plate_text = read_text_with_easyocr(plate_roi)\n",
        "                        frame = annotate_with_arabic_text(frame, plate_text, (x1 + px1, y1 + py1 - 30))\n",
        "                        cv2.rectangle(frame, (x1 + px1, y1 + py1), (x1 + px2, y1 + py2), (0, 255, 0), 2)\n",
        "\n",
        "    return frame\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Load models\n",
        "    model, plate_model, safe_driving_model = load_models()\n",
        "    if model is None or plate_model is None or safe_driving_model is None:\n",
        "        return\n",
        "\n",
        "    # Open the video file\n",
        "    video_path = \"/content/Car-Detection-main/testvideos/VID-20241216-WA0004.mp4\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Frame skipping parameters\n",
        "    skip_frames = 5  # Process every 5th frame\n",
        "    frame_counter = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        success, frame = cap.read()\n",
        "        if not success:\n",
        "            break  # End of video\n",
        "\n",
        "        frame_counter += 1\n",
        "        if frame_counter % skip_frames != 0:\n",
        "            continue  # Skip this frame\n",
        "\n",
        "        # Process the frame\n",
        "        frame = process_frame(frame, model, plate_model, safe_driving_model)\n",
        "\n",
        "        # Display the frame\n",
        "        cv2_imshow(frame)\n",
        "\n",
        "        # Break if 'q' is pressed\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "\n",
        "    # Release resources\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wT2xwrO2slc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
